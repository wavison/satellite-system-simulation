{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Acronym Finder + Dictionary Check (Notebook)\n\nThis notebook scans **one specific file** for acronyms, checks each one against an **engineering dictionary CSV**, and writes a results CSV named like your input file with `_acronyms` appended.\n\n**What you get**\n- Extracted acronyms (no guesses or internet lookups).\n- Counts of how many times each acronym appears.\n- Whether it's in the engineering dictionary.\n- The dictionary definition if found.\n\n**How to use**\n1. In the **Parameters** cell below, set `INPUT_FILE` to your document path (supports `.txt`, `.md`, `.csv`, `.xlsx`, `.docx`).\n2. (Optional) Set `DICT_CSV` if your dictionary CSV is elsewhere. By default it uses `/mnt/data/engineering_dictionary.csv`.\n3. Run the **Run** cell to generate the CSV output. The output is saved as `<input_basename>_acronyms.csv` in the same folder as the input.\n\n> If you get missing package errors, install them in a new cell:\n> ```\n> !pip install pandas openpyxl python-docx\n> ```\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import os, re, csv\nfrom collections import Counter\n\n# Optional dependencies\ntry:\n    import pandas as pd\nexcept Exception:\n    pd = None\n\ntry:\n    import docx  # python-docx\nexcept Exception:\n    docx = None\n\n# Regex to capture acronyms like NASA, GPS-III, H2O, RFC1234 (2â€“10 chars, caps/digits, optional dashes)\nACRONYM_TOKEN_RE = re.compile(r\"\\b([A-Z][A-Z0-9-]{1,9})\\b\")\n# Also catch acronyms inside parentheses e.g. (LEO), (GPS-III)\nPAREN_ACRO_RE = re.compile(r\"\\(([A-Z][A-Z0-9-]{1,9})\\)\")\n\ndef extract_acronyms_from_text(text, min_len=2, max_len=10):\n    \"\"\"Return a Counter of acronym strings (uppercased) found in text.\"\"\"\n    counts = Counter()\n    for m in ACRONYM_TOKEN_RE.finditer(text):\n        tok = m.group(1)\n        if min_len <= len(tok) <= max_len and sum(1 for ch in tok if \"A\" <= ch <= \"Z\") >= 2:\n            counts[tok.upper()] += 1\n    for m in PAREN_ACRO_RE.finditer(text):\n        tok = m.group(1)\n        if min_len <= len(tok) <= max_len and sum(1 for ch in tok if \"A\" <= ch <= \"Z\") >= 2:\n            counts[tok.upper()] += 1\n    return counts\n\ndef read_text_from_file(path):\n    \"\"\"Read all textual content from a supported single file path.\"\"\"\n    ext = os.path.splitext(path)[1].lower()\n\n    if ext in {\".txt\", \".md\"}:\n        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n            return f.read()\n\n    if ext == \".csv\":\n        if pd is None:\n            raise RuntimeError(\"pandas is required to read CSV input files.\")\n        try:\n            df = pd.read_csv(path, dtype=str, encoding=\"utf-8\", engine=\"python\")\n        except Exception:\n            df = pd.read_csv(path, dtype=str, encoding=\"latin-1\", engine=\"python\")\n        return \"\\n\".join(df.astype(str).fillna(\"\").values.flatten().tolist())\n\n    if ext == \".xlsx\":\n        if pd is None:\n            raise RuntimeError(\"pandas + openpyxl are required to read .xlsx input files.\")\n        xls = pd.ExcelFile(path, engine=\"openpyxl\")\n        parts = []\n        for sheet in xls.sheet_names:\n            try:\n                df = pd.read_excel(xls, sheet_name=sheet, dtype=str)\n                parts.append(\"\\n\".join(df.astype(str).fillna(\"\").values.flatten().tolist()))\n            except Exception:\n                continue\n        return \"\\n\".join(parts)\n\n    if ext == \".docx\":\n        if docx is None:\n            raise RuntimeError(\"python-docx is required to read .docx files.\")\n        d = docx.Document(path)\n        parts = [p.text for p in d.paragraphs]\n        for table in d.tables:\n            for row in table.rows:\n                for cell in row.cells:\n                    parts.append(cell.text)\n        return \"\\n\".join(parts)\n\n    raise ValueError(f\"Unsupported input type: {ext}\")\n\ndef guess_dictionary_columns(df):\n    \"\"\"Try to find acronym and definition columns. Returns (acro_col, def_col or None).\"\"\"\n    cols = list(df.columns)\n    low = [c.lower().strip() for c in cols]\n\n    def pick(cands, default=None):\n        for i, name in enumerate(low):\n            if any(key in name for key in cands):\n                return cols[i]\n        return default\n\n    acro_col = pick([\"acronym\", \"abbr\", \"abbrev\", \"short\", \"code\", \"initialism\"], cols[0] if cols else None)\n    def_col = pick([\"definition\", \"meaning\", \"expansion\", \"description\", \"full\", \"notes\"], None)\n\n    # If no explicit definition col, but there are >=2 columns, pick the first non-acronym one\n    if def_col is None and len(cols) >= 2:\n        for c in cols:\n            if c != acro_col:\n                def_col = c\n                break\n    return acro_col, def_col\n\ndef load_dictionary(dict_csv_path):\n    \"\"\"Load dictionary CSV -> mapping ACRONYM -> definition (case-insensitive).\"\"\"\n    if pd is None:\n        raise RuntimeError(\"pandas is required to read the dictionary CSV.\")\n    try:\n        df = pd.read_csv(dict_csv_path, dtype=str, encoding=\"utf-8\", engine=\"python\")\n    except Exception:\n        df = pd.read_csv(dict_csv_path, dtype=str, encoding=\"latin-1\", engine=\"python\")\n\n    if df.empty or df.shape[1] == 0:\n        raise RuntimeError(\"Dictionary CSV appears to be empty.\")\n\n    acro_col, def_col = guess_dictionary_columns(df)\n    if acro_col is None:\n        raise RuntimeError(\"Could not identify the acronym column in the dictionary CSV.\")\n\n    dmap = {}\n    for _, row in df.fillna(\"\").iterrows():\n        acro = str(row[acro_col]).strip()\n        if not acro:\n            continue\n        key = acro.upper()\n        definition = str(row[def_col]).strip() if def_col and def_col in row else \"\"\n        if key in dmap:\n            if definition and definition not in dmap[key]:\n                dmap[key] = dmap[key] + \"; \" + definition\n        else:\n            dmap[key] = definition\n    return dmap, df\n\ndef make_output_csv_path(input_path):\n    \"\"\"Derive output CSV path as <input_basename>_acronyms.csv in the same folder.\"\"\"\n    folder, fname = os.path.split(input_path)\n    base, _ext = os.path.splitext(fname)\n    out_name = f\"{base}_acronyms.csv\"\n    return os.path.join(folder or \".\", out_name)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# === Parameters (edit these) ===\nINPUT_FILE = r\"/path/to/your/file.docx\"   # <-- change this to your file\nDICT_CSV   = r\"/mnt/data/engineering_dictionary.csv\"  # default dictionary path\nMIN_LEN    = 2\nMAX_LEN    = 10\n\n# If needed, install deps in a separate cell:\n# !pip install pandas openpyxl python-docx\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# --- Run extraction & lookup ---\nfrom pathlib import Path\n\nif not os.path.isfile(INPUT_FILE):\n    raise FileNotFoundError(f\"INPUT_FILE not found: {INPUT_FILE}\")\n\n# Load dictionary\ndict_map, dict_df = load_dictionary(DICT_CSV)\n\n# Read input text and extract acronym counts\ntext = read_text_from_file(INPUT_FILE)\ncounts = extract_acronyms_from_text(text, min_len=MIN_LEN, max_len=MAX_LEN)\n\n# Prepare result rows\nimport pandas as pd  # ensure pandas is available for DataFrame export\nrows = []\nfor acro in sorted(counts.keys()):\n    definition = dict_map.get(acro, \"\")\n    in_dict = \"Yes\" if acro in dict_map else \"No\"\n    rows.append({\"acronym\": acro, \"count\": counts[acro], \"in_dictionary\": in_dict, \"definition\": definition})\n\ndf_out = pd.DataFrame(rows, columns=[\"acronym\", \"count\", \"in_dictionary\", \"definition\"])\n\n# Derive output path based on input\nOUT_CSV = make_output_csv_path(INPUT_FILE)\n\n# Save CSV\nos.makedirs(os.path.dirname(OUT_CSV) or \".\", exist_ok=True)\ndf_out.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n\nprint(f\"Scanned: {INPUT_FILE}\")\nprint(f\"Unique acronyms: {len(df_out)}\")\nprint(f\"Wrote: {OUT_CSV}\")\n\n# Preview first few rows\ndf_out.head(20)\n",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}